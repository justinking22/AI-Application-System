{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNkFBxzxjV3um3VqBwh+/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justinking22/AI-Application-System/blob/main/week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pg5GWiC6kdft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(3) #To make repeatable LEARNING_RATE=0.1\n",
        "\n",
        "index_list=[0,1,2,3] #Used to randomize order\n",
        "\n",
        "\n",
        "#Define training examples \n",
        "\n",
        "x_train=[np.array([1.0,-1.0,-1.0]),\n",
        "         np.array([1.0,1.0, -1.0]),\n",
        "         np.array([1.0,1.0,1.0])]\n",
        "y_train=[0.0, 1.0, 1.0, 0.0] #Output(ground truth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neuron_w(input_count):\n",
        "  weights = np.zeros(input_count+1) \n",
        "  for i in range(1,\n",
        "  (input_count+1)):\n",
        "    weights[i]=np.random.uniform(-1.0, 1.0) \n",
        "    return weights\n",
        "\n",
        "n_w=[neuron_w(2),\n",
        "     neuron_w(2),\n",
        "     neuron_w(2)]\n",
        "n_y = [0,0,0]\n",
        "n_error=[0,0,0]"
      ],
      "metadata": {
        "id": "6eoitc-6lnyW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_learning():\n",
        "  print('Current weights:')\n",
        "  for i, w in enumerate(n_w):\n",
        "    print('neuron',i, ':w0=','%5.2f'%w[0],\n",
        "          ',w1=','%5.2f'%w[1],',w2=','%5.2'%w[2])\n",
        "    \n",
        "  print('-----------')\n",
        "\n",
        "def forward_pass(x):\n",
        "  global n_y\n",
        "  n_y[0]=np.tanh(np.dot(n_w[0],x)) #Neuron\n",
        "  n_y[1]=np.tanh(np.dot(n_w[1],x)) #Neuron 1\n",
        "  n2_inputs=np.array([1.0,n_y[0],n_y[1]]) #1.0 is bias\n",
        "  z2=np.dot(n_w[2],n2_inputs)\n",
        "\n",
        "  ny_[2]=1.0/(1.0+np.exp(-z2))\n",
        "def backward_pass(y_truth): \n",
        "    global n_error\n",
        "    error_prime = -(y_truth - n_y[2]) #Derivative of loss-func\n",
        "    derivative = n_y[2]*(1.0-n_y[2])  #Logistic derivative \n",
        "    n_error[2]=error_prime * derivative\n",
        "    derivative=1.0-n_y[0]**2 #tanh derivative\n",
        "    n_error[0]=n_w[2][1]*n_error[2]*derivative\n",
        "    derivative=1.0-n_y[1]**2 #tanh derivative\n",
        "    n_error[1]=n_w[2][2]*n_error[2]*derivative\n",
        "def adjust_weights(x):\n",
        "  global n_w\n",
        "\n",
        "  n_w[0]-=(x*LEARNING_RATE*n_error[0])\n",
        "  n_w[1]-=(x*LEARNING_RATE*n_error[1])\n",
        "  n2_inputs=np.array([1.0, n_y[0],n_y[1]])#1.0 is bias\n",
        "\n",
        "  n_w[2]-=(n2_inputs*LEARNING_RATE*n_error[2])"
      ],
      "metadata": {
        "id": "1cwC9wRoyDx_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEVVez2T4ep1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}